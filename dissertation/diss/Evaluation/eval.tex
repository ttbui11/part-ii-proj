\chapter{Evaluation}
\textit{This chapter assesses the functionality of my implementation in simulation and in hardware with regard to the initial requirements. I then evaluate the performance of my design. Finally, I compare its performance to existing TCP fast retransmit mechanism.}

The objective of this chapter is to review Unbuckleâ€™s success at meeting the original project success criteria and at delivering benefits over state-of-the-art key-value stores. Hence, I begin by discussing the original project success criteria and how Unbuckle meets (and exceeds) them. Then, I briefly discuss the testing strategies applied. An extensive quantitative evaluation to assess the performance impact of various optimisations is carried out. Finally, I compare the user-space and kernel versions of Unbuckle, and show that it outperforms contemporary optimised commercial key- value stores. Comparisons against research systems are also made, where I find Unbuckle is competitive.

\section{Simulation Environment}
It is generally easier to debug program behaviour in simulation than in hardware, and the purpose of the simulation environment is exactly that. For this purpose, the P4$\rightarrow$NetFPGA workflow provides a simulation environment with automated test benches. To run a simulation, we will provide the corresponding test bench with the testing scripts. We will modify the following files:

\begin{itemize}
	\item \texttt{commands.txt} contains the set of commands to add entries to the match-action tables that we have defined in our P4 program (see Table \ref{}). These entries will be automatically added to the P4 tables at the start of each simulation. 
	\item \texttt{gen\_testdata.py} generates test packets (\& metadata), along with the corresponding expected output packets and metadata.
	\item \texttt{run.py} reads the test packets generated by the \texttt{gen\_testdata.py} script and applies the packets to the SUME interfaces.
\end{itemize}

The \texttt{gen\_testdata.py} template provided by the P4$\rightarrow$NetFPGA workflow has two functions--- \verb|applyPkt()| and \verb|expPkt()|---which allow us to specify input packets and expected output packets respectively. I wrote the \verb|digest_data.py| module and use Python \texttt{scapy} module to generate the metadata and test packets. The following code sequence shows an example of how to create and send a test packet, and specify the expected packet. We create the test packet using \texttt{scapy}'s \texttt{Ether}, \texttt{IP} and \texttt{TCP} classes, stacking the layer using the \texttt{/} operator and pad it to 64 bytes using \texttt{pad\_pkt()} method. Then, \verb|applyPkt()| will ``send'' the packet to the SimpleSumeSwitch module. Now, we need to specify how we would expect the output packet. We create two variables, \verb|flow_id| and \verb|actions|, to represent the value of the flow number and the \texttt{tuser} bus of the output packet. Finally, we use \verb|expPkt()| to put the packet into a list of ``expect'' packets.

{\renewcommand{\baselinestretch}{0.8}\small
	\begin{verbatim}
    from scapy.all import *
    from digest_data import *
	
    MAC_src = "08:11:11:11:11:08"  # nf0
    MAC_dst = "08:22:22:22:22:08"  # nf1
    sport = 55
    dport = 75
    IP_src = "10.0.0.1"
    IP_dst = "10.0.0.2"
	
    pkt = (
      Ether(src=MAC_src, dst=MAC_dst)
      / IP(src=IP_src, dst=IP_dst)
      / TCP(sport=sport, dport=dport, flags="S", seq=1)
    )                              # create the packet using scapy Ether, IP and TCP classes.
    pkt = pad_pkt(pkt, 64)         # pad the packet to 64 bytes
    applyPkt(pkt, "nf0", 0)        # send from port 0

    # compute the flow number
    flow_id = compute_flow_number(IP1_src, IP1_dst, 6, sport, dport)
    
    # write to port 1 of cache_queue
    actions = compute_tuser(0, 0, 0, tuser_map["nf1"])             
    
    # expect from port 1 of output_queue
    expPkt(pkt, "nf1", drop=False, flow_id=flow_id, tuser=actions)
	\end{verbatim}
}

Once the packets and metadata have been produced, we run two stages of simulation: SDNet simulation and SUME simulation.

\subsection{SDNet Simulation}
The SDNet simulation will compile the P4 code and simulate its behaviour. It is done by running the test bench produced by the SDNet compiler. This will first compile the code. After successful compilation, it then ``send'' the user defined input packets and metadata to the SimpleSumeSwitch HDL module and compare the outputs with the expected outputs. 

To simulate the behaviour of our switch under different scenarios, I wrote five test cases which I will now discuss the goal and the description of the test case, and present the output. For the purpose of the simulation, our flow of interest will be from MAC address \texttt{08:11:11:11:11:08}, IP address \texttt{10.0.0.1} and port 55 to MAC address \texttt{08:22:22:22:22:08}, IP address \texttt{10.0.0.2} and port 75.

NOTE: Show snapshots of the wave windows with arrows pointing to different important indications. I have not finished this. I will take snapshots of relevant part and put here. Would you prefer writing the test case in prose or in bullet points 

The first test case simulates the basic packet forwarding of the P4 program. We send one packet from port 0 to port 1 and expect to receive one packet coming out of port 1 of the SimpleSumeSwitch module. This packet should have:
\begin{itemize}
	\item The \verb|digest_data.flow_id| field computed to the binary representation of the flow number of the packet. Every packet that comes through the SimpleSumeSwitch module should have its flow number computed to decide whether it is the packet of the flow of interest.
	\item The \verb|digest_data.tuser| set to write the packet to the port 1 of the cache queue. Since this packet is of the flow of interest, we need to cache it to retransmit if necessary. 
\end{itemize} 

OR

Test \#1: Basic packet forwarding of the SimpleSumeSwitch-architecture-based P4 program
Goal: A packet coming through the SSS architecture will come out with the \texttt{digest\_data} modified.
Description:
\begin{itemize}
\item Send 1 packet from port 0 to port 1.
\item Expect 1 packet coming out of port 1 of the SSS with the \texttt{digest\_data.flow\_id} computed and matches the flow number of the original packet, and the \texttt{digest\_data.tuser} set to write the packet to the cache queue of port 1.
\end{itemize}

%\begin{figure}[!ht]
%	\centering
%	\includegraphics[width=\textwidth]{test1.png}
%	\caption{Test \#1: Basic packet forwarding of the SimpleSumeSwitch architecture-based P4 program.}
%	\label{test1}
%\end{figure}

The second test case.
%\begin{figure}[!ht]
%	\centering
%	\includegraphics[width=\textwidth]{test2.png}
%	\caption{Test \#2: Behaviour of the program when it receives a standard ACK packet.}
%	\label{test2}
%\end{figure}

The third test case.
%\begin{figure}[!ht]
%	\centering
%	\includegraphics[width=\textwidth]{test3.png}
%	\caption{Test \#3: Behaviour of the program when three DUP ACK packets are received.}
%	\label{test3}
%\end{figure}

The fourth test case.
%\begin{figure}[!ht]
%	\centering
%	\includegraphics[width=\textwidth]{test4.png}
%	\caption{Test \#4: Behaviour of the program when a fourth DUP ACK is received.}
%	\label{test4}
%\end{figure}

The fifth test case.
%\begin{figure}[!ht]
%	\centering
%	\includegraphics[width=\textwidth]{test5.png}
%	\caption{Test \#5: Behaviour of the program when there are multiple flows.}
%	\label{test5}
%\end{figure}

\subsection{SUME simulation}
Once the code passes the SDNet simulation (i.e. the actual outputs are the same as the expected outputs), the SUME simulation will install the SimpleSumeSwitch HDL module as a NetFPGA IP core and simulate the behaviour of the entire NetFPGA reference switch design. This simulation can also be done by running another test bench produced by the P4-SDNet toolchain. It uses the same stimuli and comparisons to verify that the SimpleSumeSwitch module was successfully integrated into our modified reference switch pipeline. 

The same five test cases were used to simulate the switch behaviour in our reference design, with the output shows success. The only noticeable difference is in test case \#4. 

\section{Hardware Test}
After all simulations indicate that the program is behaving correctly, the hardware test allows the design to be tested on the NetFPGA SUME board. 

I built the FPGA bitstream and started testing the design on hardware.

\section{Performance Evaluation}
\section{Comparison with TCP}

